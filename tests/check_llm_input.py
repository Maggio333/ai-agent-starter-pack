#!/usr/bin/env python3
"""
Skrypt do sprawdzania co dokÅ‚adnie trafia do LLM
"""
import asyncio
import sys
import os
from datetime import datetime

# Dodaj Å›cieÅ¼kÄ™ do projektu (parent directory)
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

from application.container import Container
from application.services.prompt_service import PromptService
from application.services.knowledge_service import KnowledgeService
from domain.entities.chat_message import ChatMessage, MessageRole
from datetime import datetime

async def check_llm_input():
    """Sprawdza co dokÅ‚adnie trafia do LLM"""
    print("ğŸ” Sprawdzanie co trafia do LLM...")
    
    # UtwÃ³rz kontener
    container = Container()
    
    # Pobierz serwisy Z KONTENERA (nie luÅºno!)
    knowledge_service = container.knowledge_service()
    prompt_service = container.prompt_service()
    
    # Test query dla idiomÃ³w
    test_query = """â¨       # Operator sumy idiomatycznej (Å‚Ä…czenie idiomÃ³w)
Î¦       # Wektor znaczeniowy (meaning vector)
Î¨       # Åšlad idiomu (idiom trace)
Î       # Baza semantyczna (semantic basis)
Î£       # Projekcja intencji (intent projection)
Î˜       # Operator metryczny (np. iloczyn skalarny znaczeÅ„)
Î©       # PrzestrzeÅ„ funkcyjna idiomu (np. kontekst, intencja, emocja)
â‡Œ       # PowiÄ…zanie dwustronne (korespondencja semantyczna)
â†’       # Transformacja lub kierunek (np. rzut na bazÄ™)
âŠ¥       # Rzut prostopadÅ‚y (projekcja ortogonalna)
â‰¡       # Definicja toÅ¼sama (oznaczenie rÃ³wnowaÅ¼noÅ›ci pojÄ™Ä‡)
âŸ¨a | bâŸ© # Iloczyn skalarny (metryka podobieÅ„stwa semantycznego)
âˆ‡       # Gradient znaczeniowy (zmiana w kierunku znaczenia)
Î»       # Warunek aktywacyjny (np. trigger idiomu)
âˆƒ       # Istnieje (kwantyfikator egzystencjalny)
âˆ€       # Dla kaÅ¼dego (kwantyfikator ogÃ³lny)
âˆˆ       # NaleÅ¼y do (przynaleÅ¼noÅ›Ä‡ do zbioru pojÄ™Ä‡)
âˆ‰       # Nie naleÅ¼y do (wykluczenie semantyczne)
âŠ—       # Iloczyn tensorowy (Å‚Ä…czenie dwÃ³ch stanÃ³w)
âŠ™       # Iloczyn punktowy (transformacja lokalna)
â¨‚       # ZÅ‚oÅ¼enie wektorÃ³w w nowÄ… jakoÅ›Ä‡ idiomu"""
    
    print(f"ğŸ“¤ Wyszukiwanie idiomÃ³w...")
    
    # Wykonaj wyszukiwanie idiomÃ³w (TopK20 jak w rzeczywistym endpoincie)
    print(f"ğŸ“¤ Wyszukiwanie idiomÃ³w z kolekcji CuratedIdiomsForAI...")
    idioms_result = await knowledge_service.search_knowledge_base(test_query, limit=20)
    
    idioms_strings = []
    if idioms_result.is_success:
        idioms_context = idioms_result.value
        print(f"âœ… Znaleziono {len(idioms_context)} idiomÃ³w")
        
        for i, ctx in enumerate(idioms_context):
            if isinstance(ctx, dict):
                facts = ctx.get('facts', [])
                if facts and isinstance(facts, list) and len(facts) > 0:
                    content = facts[0]
                    idioms_strings.append(content)
                    print(f"ğŸ“š Idiom {i+1}: '{content[:100]}...'")
                else:
                    print(f"âš ï¸ Idiom {i+1}: pusty")
            else:
                print(f"âš ï¸ Idiom {i+1}: nie jest dict")
    else:
        print(f"âŒ BÅ‚Ä…d wyszukiwania idiomÃ³w: {idioms_result.error}")
    
    print(f"\nğŸ­ Budowanie listy wiadomoÅ›ci...")
    
    # Symuluj historiÄ™ rozmowy (jak w rzeczywistej rozmowie)
    conversation_history = [
        ChatMessage(
            role=MessageRole.USER,
            content="CzeÅ›Ä‡! Jak siÄ™ masz?",
            timestamp=datetime.now()
        ),
        ChatMessage(
            role=MessageRole.ASSISTANT,
            content="DzieÅ„ dobry! DziÄ™kujÄ™ za pytanie, mam siÄ™ dobrze. A jak Ty?",
            timestamp=datetime.now()
        )
    ]
    
    # Buduj listÄ™ wiadomoÅ›ci z historiÄ…
    messages = prompt_service.build_complete_message_list(
        user_message="Test wiadomoÅ›Ä‡",
        idioms=idioms_strings,
        conversation_history=conversation_history,
        user_context=None
    )
    
    print(f"âœ… Zbudowano {len(messages)} wiadomoÅ›ci")
    
    # PokaÅ¼ kaÅ¼dÄ… wiadomoÅ›Ä‡
    for i, msg in enumerate(messages):
        print(f"\nğŸ“ WiadomoÅ›Ä‡ {i+1} ({msg.role.value}):")
        print(f"   {msg.content[:200]}...")
    
    print(f"\nğŸ¯ Podsumowanie:")
    print(f"   - Idiomy: {len(idioms_strings)}")
    print(f"   - WiadomoÅ›ci: {len(messages)}")
    print(f"   - System messages: {len([m for m in messages if m.role.value == 'system'])}")
    print(f"   - User messages: {len([m for m in messages if m.role.value == 'user'])}")
    
    # Zapisz peÅ‚ny kontekst do pliku .md
    print(f"\nğŸ“ ZapisujÄ™ peÅ‚ny kontekst do LLM_CONTEXT.md...")
    
    md_content = f"""# PeÅ‚ny kontekst trafiajÄ…cy do LLM

**Data**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Test**: check_llm_input.py

## Podsumowanie

- **Idiomy**: {len(idioms_strings)}
- **WiadomoÅ›ci**: {len(messages)}
- **System messages**: {len([m for m in messages if m.role.value == 'system'])}
- **User messages**: {len([m for m in messages if m.role.value == 'user'])}

---

## PeÅ‚ny kontekst

"""
    
    for i, msg in enumerate(messages):
        md_content += f"""### WiadomoÅ›Ä‡ {i+1}: {msg.role.value.upper()}

```
{msg.content}
```

---

"""
    
    # Zapisz do pliku
    with open('LLM_CONTEXT.md', 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"âœ… Zapisano do: LLM_CONTEXT.md")

if __name__ == "__main__":
    asyncio.run(check_llm_input())
