# Environment Configuration for ATSReflectumAgentStarterPack
# Copy this file to .env and fill in your actual values

# ============================================================================
# ENVIRONMENT & GENERAL CONFIGURATION
# ============================================================================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
API_HOST=0.0.0.0
API_PORT=8080
FRONTEND_PORT=3000
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
BATCH_SIZE=32
EMBEDDING_BATCH_SIZE=16

# ============================================================================
# BUDGET PREFERENCE
# ============================================================================
# Options: free, low, medium, high
# Affects recommended provider selection
BUDGET_PREFERENCE=free

# ============================================================================
# LLM SERVICE CONFIGURATION
# ============================================================================
LLM_PROVIDER=lmstudio
# Dla lokalnego uruchomienia:
# LMSTUDIO_LLM_PROXY_URL=http://127.0.0.1:8123
# Dla Docker (LM Studio na hoście):
LMSTUDIO_LLM_PROXY_URL=http://host.docker.internal:8123
LMSTUDIO_LLM_MODEL_NAME=model:1

# Alternative LLM Providers (uncomment to use)
# LLM_PROVIDER=google
# GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_LLM_MODEL=gemini-2.0-flash
# GOOGLE_PROJECT_ID=your_google_project_id

# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key
# OPENAI_LLM_MODEL=gpt-3.5-turbo

# LLM_PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama2

# LLM_PROVIDER=local
# LOCAL_LLM_MODEL_PATH=/path/to/local/model

# ============================================================================
# EMBEDDING SERVICE CONFIGURATION
# ============================================================================
EMBEDDING_PROVIDER=lmstudio
# Dla lokalnego uruchomienia:
# LMSTUDIO_PROXY_URL=http://127.0.0.1:8123
# Dla Docker (LM Studio na hoście):
LMSTUDIO_PROXY_URL=http://host.docker.internal:8123
LMSTUDIO_MODEL_NAME=model:10

# Alternative Embedding Providers (uncomment to use)
# EMBEDDING_PROVIDER=huggingface
# HUGGINGFACE_MODEL_NAME=all-MiniLM-L6-v2

# EMBEDDING_PROVIDER=google
# GOOGLE_EMBEDDING_MODEL=textembedding-gecko@001
# GOOGLE_API_KEY=your_google_api_key_here
# GOOGLE_PROJECT_ID=your_google_project_id

# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key
# OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# EMBEDDING_PROVIDER=local
# LOCAL_MODEL_PATH=/path/to/local/embedding/model
# LOCAL_DEVICE=auto

# ============================================================================
# VECTOR DATABASE CONFIGURATION
# ============================================================================
VECTOR_DB_PROVIDER=qdrant
# Dla lokalnego uruchomienia:
# QDRANT_URL=http://localhost:6333
# Dla Docker:
QDRANT_URL=http://qdrant:6333
# Kolekcje:
# - CuratedIdiomsForAI: Kolekcja idiomów (hardcoded w kodzie)
# - PierwszaKolekcjaOnline: Standardowa kolekcja dla dynamic RAG (LOCAL_SEARCH_INDEX)
QDRANT_COLLECTION_NAME=chat_collection
QDRANT_API_KEY=

# Alternative Vector DB Providers (uncomment to use)
# VECTOR_DB_PROVIDER=chroma
# CHROMA_PERSIST_DIRECTORY=./chroma_db
# CHROMA_COLLECTION_NAME=chat_collection

# VECTOR_DB_PROVIDER=faiss
# FAISS_INDEX_PATH=./faiss_index
# FAISS_INDEX_TYPE=FlatL2

# VECTOR_DB_PROVIDER=pinecone
# PINECONE_API_KEY=your_pinecone_api_key
# PINECONE_ENVIRONMENT=your_environment
# PINECONE_INDEX_NAME=chat_index

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
DATABASE_TYPE=sqlite
DATABASE_PATH=chat.db
DATABASE_URL=sqlite:///chat.db

# Alternative Database (PostgreSQL) - uncomment to use
# DATABASE_TYPE=postgresql
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DB=chat_db
# POSTGRES_USER=chat_user
# POSTGRES_PASSWORD=your_postgres_password

# ============================================================================
# CACHE SERVICE CONFIGURATION
# ============================================================================
CACHE_PROVIDER=memory
MEMORY_CACHE_SIZE=1000
MEMORY_CACHE_TTL=3600

# Alternative Cache (Redis) - uncomment to use
# CACHE_PROVIDER=redis
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=
# REDIS_DB=0
# REDIS_URL=redis://localhost:6379

# ============================================================================
# SEARCH SERVICE CONFIGURATION
# ============================================================================
SEARCH_PROVIDER=local
# Standardowa kolekcja dla dynamic RAG (używana przez KnowledgeService)
# Uwaga: Idiomy są w kolekcji "CuratedIdiomsForAI" (hardcoded w kodzie)
LOCAL_SEARCH_INDEX=PierwszaKolekcjaOnline

# Alternative Search Providers (uncomment to use)
# SEARCH_PROVIDER=whoosh
# WHOOSH_INDEX_NAME=default
# WHOOSH_INDEX_DIR=./whoosh_index

# SEARCH_PROVIDER=elasticsearch
# ELASTICSEARCH_INDEX=default
# ELASTICSEARCH_URL=http://localhost:9200
# ELASTICSEARCH_API_KEY=

# SEARCH_PROVIDER=solr
# SOLR_COLLECTION=default
# SOLR_URL=http://localhost:8983
# SOLR_API_KEY=

# SEARCH_PROVIDER=algolia
# ALGOLIA_INDEX=default
# ALGOLIA_APP_ID=your_algolia_app_id
# ALGOLIA_API_KEY=your_algolia_api_key

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================
# Generate secure keys for production use
# You can generate them using: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=
JWT_SECRET=
ENCRYPTION_KEY=

# ============================================================================
# MONITORING CONFIGURATION
# ============================================================================
ENABLE_METRICS=true
METRICS_PORT=9090
HEALTH_CHECK_INTERVAL=30

# ============================================================================
# FEATURE FLAGS
# ============================================================================
ENABLE_CACHING=true
ENABLE_MONITORING=true
ENABLE_RATE_LIMITING=true
